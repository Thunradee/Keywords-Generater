{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keywords Generation From PDF File  \n",
    "\n",
    "## Introduction\n",
    "This notebook aims to generate keywords for scientific papers that posted online as PDF files. We do this by\n",
    "\n",
    "1. <b>Getting Data</b> - we collect a url of papers from our database.\n",
    "2. <b>Keywords Generation</b>  \n",
    "    We try generating keywords by using data engineering and machine learning libraries.  \n",
    "  - Keywords matching - We read in content of online pdf file, then count occurrence of each word in our pre-listed keywords list and select 5 highest words.  \n",
    "  - SpaCy\n",
    "  - YAKE\n",
    "  - Rake-Nltk\n",
    "  - Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect with database\n",
    "from pymongo import MongoClient\n",
    "\n",
    "DB_NAME = 'TechVault'\n",
    "COLLECTION_NAME = 'blogs'\n",
    "\n",
    "mongo_uri = \"\"\n",
    "client = MongoClient(mongo_uri)\n",
    "\n",
    "# Database: TechVault\n",
    "db = client[DB_NAME]\n",
    "\n",
    "# Collection: blogs\n",
    "collection = db[COLLECTION_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://arxiv.org/pdf/0704.0002'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all papers\n",
    "\n",
    "papers = []\n",
    "\n",
    "for doc in collection.find():\n",
    "    if doc['type'] == 'paper':\n",
    "        # collect only title and abstract\n",
    "        paper = {'url': doc['link']}\n",
    "        papers.append(paper)\n",
    "\n",
    "papers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284703"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Keywords Generation\n",
    "### 2.1 Keywords Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of keywords\n",
    "# Key: Searching words\n",
    "# Value: Displayed words\n",
    "\n",
    "keywords = {\"Machine Learning\": \"Machine Learning\",\n",
    "            \"Supervised Learning\": \"Supervised Learning\",\n",
    "            \"Unsupervised Learning\": \"Unsupervised Learning\",\n",
    "            \"Multilabel Classification\": \"Multilabel Classification\",\n",
    "            \"Clustering\": \"Clustering\",\n",
    "            \"K-Means\": \"K-Means\",\n",
    "            \"DBSCAN\": \"DBSCAN\",\n",
    "            \"Hierarchical Clustering\": \"Hierarchical Clustering\",\n",
    "            \"Deep Learning\": \"Deep Learning\",\n",
    "            \"Data Mining\": \"Data Mining\",\n",
    "            \"Linear regression\": \"Linear regression\",\n",
    "            \"Logistic regression\": \"Logistic regression\",\n",
    "            \"SVM\": \"SVM\",\n",
    "            \"Natural Language Processing\": \"Natural Language Processing\",\n",
    "            \"Computer Vision\": \"Computer Vision\",\n",
    "            \"KNN\": \"KNN\",\n",
    "            \"Random forest\": \"Random forest\",\n",
    "            \"Decision Tree\": \"Decision Tree\",\n",
    "            \"Regularization\": \"Regularization\",\n",
    "            \"Ensemble Learning\": \"Ensemble Learning\",\n",
    "            \"Gradient Boosting\": \"Gradient Boosting\",\n",
    "            \"Feature Selection\": \"Feature Selection\",\n",
    "            \"Reinforcement Learning\": \"Reinforcement Learning\",\n",
    "            \"Virtual Reality\": \"Virtual Reality\",\n",
    "            \"Augmented reality\": \"Augmented reality\",\n",
    "            \"Autonomous driving\": \"Autonomous driving\",\n",
    "            \"Optics\": \"Optics\",\n",
    "            \"Biology\": \"Biology\",\n",
    "            \"C++\": \"C++\",\n",
    "            \"Java\": \"Java\",\n",
    "            \"Python\": \"Python\",\n",
    "            \"React JS\": \"React JS\",\n",
    "            \"Computer Network\": \"Computer Networks\",  # remove s\n",
    "            \"Frontend\": \"Frontend\",\n",
    "            \"Backend\": \"Backend\",\n",
    "            \"High Scalability\": \"High Scalability\",\n",
    "            \"Cloud computing\": \"Cloud computing\",\n",
    "            \"Parallel Computing\": \"Parallel Computing\",\n",
    "            \"CUDA\": \"CUDA\",\n",
    "            \"Distributed System\": \"Distributed Systems\",  # remove s\n",
    "            \"Apache ZooKeeper\": \"Apache ZooKeeper\",\n",
    "            \"Streaming analytic\": \"Streaming analytics\",\n",
    "            \"Model Selection\": \"Model Selection\",\n",
    "            \"Model Evaluation\": \"Model Evaluation\",\n",
    "            \"Apache Kafka\": \"Apache Kafka\",\n",
    "            \"HDFS\": \"HDFS\",\n",
    "            \"Amazon S3\": \"Amazon S3\",\n",
    "            \"Pub-Sub\": \"Pub-Sub\",\n",
    "            \"Leader Election\": \"Leader Election\",\n",
    "            \"Clock Synchronization\": \"Clock Synchronization\",\n",
    "            \"Graph\": \"Graphs\",  # remove s\n",
    "            \"Information Retrieval\": \"Information Retrieval\",\n",
    "            \"SQL\": \"SQL\",\n",
    "            \"Graph Database\": \"Graph Database\",\n",
    "            \"Database Management\": \"Database Management\",\n",
    "            \"Storage\": \"Storage\",\n",
    "            \"Memor\": \"Memory\",\n",
    "            \"Garbage Collection\": \"Garbage Collection\",\n",
    "            \"Map-Reduce\": \"Map-Reduce\",\n",
    "            \"Network Protocol\": \"Network Protocols\",  # remove s\n",
    "            \"Cyber Security\": \"Cyber Security\",\n",
    "            \"Assembly Language\": \"Assembly Language\",\n",
    "            \"Computational Complexity Theor\": \"Computational Complexity Theory\",\n",
    "            \"Computer Architecture\": \"Computer Architecture\",\n",
    "            \"Human-Computer Interface\": \"Human-Computer Interface\",\n",
    "            \"Data Structure\": \"Data Structures\",  # remove s\n",
    "            \"Discrete Mathematic\": \"Discrete Mathematics\",\n",
    "            \"Hacking\": \"Hacking\",\n",
    "            \"Quantum Computing\": \"Quantum Computing\",\n",
    "            \"Robotic\": \"Robotics\",  # remove s\n",
    "            \"Engineering Practice\": \"Engineering Practices\",  # remove s\n",
    "            \"Software Tool\": \"Software Tools\",  # remove s\n",
    "            \"Mathematical Logic\": \"Mathematical Logic\",\n",
    "            \"Graph Theor\": \"Graph Theory\",\n",
    "            \"Computational Geometr\": \"Computational Geometry\",\n",
    "            \"Compiler\": \"Compilers\",  # remove s\n",
    "            \"Distributed Computing\": \"Distributed Computing\",\n",
    "            \"Software Engineering\": \"Software Engineering\",\n",
    "            \"Bioinformatic\": \"Bioinformatics\",  # remove s\n",
    "            \"Computational Chemistry\": \"Computational Chemistry\",\n",
    "            \"Computational Neuroscience\": \"Computational Neuroscience\",\n",
    "            \"Computational physics\": \"Computational physics\",\n",
    "            \"Numerical algorithm\": \"Numerical algorithms\",  # remove s\n",
    "            \"JavaScript\": \"JavaScript\",\n",
    "            \"HTML\": \"HTML\",\n",
    "            \"Web Development\": \"Web Development\",\n",
    "            \"App Development\": \"App Development\",\n",
    "            \"CSS\": \"CSS\",\n",
    "            \"PHP\": \"PHP\",\n",
    "            \"BlockChain\": \"BlockChain\",\n",
    "            \"Hardware\": \"Hardware\",\n",
    "            \"VLSI\": \"VLSI\",\n",
    "            \"Cluster Computing\": \"Cluster Computing\",\n",
    "            \"Kubernetes\": \"Kubernetes\",\n",
    "            \"Go\": \"Go-Lang\",\n",
    "            \"File System\": \"File Systems\",  # remove s\n",
    "            \"Statistic\": \"Statistics\",  # remove s\n",
    "            \"Optimization\": \"Optimization\",\n",
    "            \"Knowledge Graph\": \"Knowledge Graph\",\n",
    "            \"RNN\": \"RNN\",\n",
    "            \"CNN\": \"CNN\",\n",
    "            \"Physical Design\": \"Physical Design\",\n",
    "            \"Memory management\": \"Memory management\",\n",
    "            \"PCA\": \"PCA\",\n",
    "            \"LDA\": \"LDA\",\n",
    "            \"Feature Engineering\": \"Feature Engineering\",\n",
    "            \"Data manipulation\": \"Data manipulation\",\n",
    "            \"ACID\": \"ACID\",\n",
    "            \"BASE\": \"BASE\",\n",
    "            \"Consistency\": \"Consistency\",\n",
    "            \"Disaster recovery\": \"Disaster recovery\",\n",
    "            \"Replication\": \"Replication\",\n",
    "            \"Fault tolerance\": \"Fault tolerance\",\n",
    "            \"Deployment\": \"Deployment\",\n",
    "            \"Processor\": \"Processors\",  # remove s\n",
    "            \"Multi-Threading\": \"Multi-Threading\",\n",
    "            \"Queue\": \"Queue\",\n",
    "            \"Stack\": \"Stack\",\n",
    "            \"Dynamic Programming\": \"Dynamic Programming\",\n",
    "            \"Graph Traversal\": \"Graph Traversal\",\n",
    "            \"Device\": \"Devices\",  # remove s\n",
    "            \"Data analysis\": \"Data analysis\",\n",
    "            \"Probability\": \"Probability\",\n",
    "            \"Mathematic\": \"Mathematics\",  # remove s\n",
    "            \"Genomic\": \"Genomics\",  # remove s\n",
    "            \"Data Infrastructure\": \"Data Infrastructure\",\n",
    "            \"Software Principles and Practices\": \"Software Principles and Practices\",\n",
    "            \"Image Processing\": \"Image Processing\",\n",
    "            \"Audio Processing\": \"Audio Processing\",\n",
    "            \"Signal Processing\": \"Signal Processing\",\n",
    "            \"Pattern Recognition\": \"Pattern Recognition\",\n",
    "            \"Computation and Language\": \"Computation and Language\",\n",
    "            \"Artificial Intelligence\": \"Artificial Intelligence\",\n",
    "            \"Computation and Language\": \"Computation and Language\",\n",
    "            \"Computational Complexit\": \"Computational Complexity\",\n",
    "            \"Computational Engineering\": \"Computational Engineering\",\n",
    "            \"Finance\": \"Finance\",  # remove \"and Science\" from \"Finance, and Science\"\n",
    "            \"Computational Geometry\": \"Computational Geometry\",\n",
    "            \"Game Theory\": \"Game Theory\",  # remove \"Computer Science\" from \"Computer Science and Game Theory\"\n",
    "            \"Computer Vision\": \"Computer Vision\",  # break down from \"Computer Vision and Pattern Recognition\"\n",
    "            \"Pattern Recognition\": \"Pattern Recognition\",  # break down from \"Computer Vision and Pattern Recognition\"\n",
    "            \"Computers and Society\": \"Computers and Society\",\n",
    "            \"Cryptography and Security\": \"Cryptography and Security\",\n",
    "            \"Data Structure\": \"Data Structures\",  # break down from \"Data Structures and Algorithms\"\n",
    "            \"Algorithm\": \"Algorithms\",  # break down from \"Data Structures and Algorithms\"\n",
    "            \"Database\": \"Databases\",  # break down from \"Databases; Digital Libraries\"\n",
    "            \"Digital Librar\": \"Digital Libraries\",  # break down from \"Databases; Digital Libraries\"\n",
    "            \"Distributed Computing\": \"Distributed Computing\",  # break down from \"Distributed, Parallel, and Cluster Computing\"\n",
    "            \"Parallel Computing\": \"Parallel Computing\",  # break down from \"Distributed, Parallel, and Cluster Computing\"\n",
    "            \"Cluster Computing\": \"Cluster Computing\",  # break down from \"Distributed, Parallel, and Cluster Computing\"\n",
    "            \"Emerging Technolog\": \"Emerging Technologies\",\n",
    "            \"Formal Language\": \"Formal Languages\",  # break down from \"Formal Languages and Automata Theory\"\n",
    "            \"Automata Theory\": \"Automata Theory\",  # break down from \"Formal Languages and Automata Theory\"\n",
    "            \"General Literature\": \"General Literature\",\n",
    "            \"Graphic\": \"Graphics\",  # remove s\n",
    "            \"Human-Computer Interaction\": \"Human-Computer Interaction\",\n",
    "            \"Information Theory\": \"Information Theory\",\n",
    "            \"Logic in Computer Science\": \"Logic in Computer Science\",\n",
    "            \"Mathematical Software\": \"Mathematical Software\",\n",
    "            \"Multiagent System\": \"Multi-agent Systems\",  # remove s from \"Systems\"\n",
    "            \"Multi-agent System\": \"Multi-agent Systems\",  # remove s from \"Systems\" and add -\n",
    "            \"Multimedia\": \"Multimedia\",\n",
    "            \"Networking and Internet Architecture\": \"Networking and Internet Architecture\",\n",
    "            \"Neural and Evolutionary Computing\": \"Neural and Evolutionary Computing\",\n",
    "            \"Numerical Analysis\": \"Numerical Analysis\",\n",
    "            \"Operating System\": \"Operating Systems\",  # remove s from \"Systems\"\n",
    "            \"Performance\": \"Performance\",\n",
    "            \"Programming Language\": \"Programming Languages\",  # remove s \n",
    "            \"Social and Information Networks\": \"Social and Information Networks\",\n",
    "            \"Software Engineering\": \"Software Engineering\",\n",
    "            \"Sound\": \"Sound\",\n",
    "            \"Symbolic Computation\": \"Symbolic Computation\",\n",
    "            \"Systems and Control\": \"Systems and Control\"\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countKeywords(text, keywords):\n",
    "    ''' Count occurence of keywords in the text, return a dict of words and its occurence'''\n",
    "    d = {}\n",
    "    text = ' ' + text + ' '\n",
    "    # Abbreviations list\n",
    "    abbreviations = [\"SVM\", \"KNN\", \"CUDA\", \"HDFS\", \"SQL\", \"HTML\", \"CSS\", \"PHP\",\n",
    "                    \"VLSI\", \"RNN\", \"CNN\", \"PCA\", \"LDA\", \"ACID\", \"BASE\"]\n",
    "    \n",
    "    for search_word, display_word in keywords.items():\n",
    "        # 'Go' can be a sub-string of many words, to be precise, we'll search for the word \" Go \"\n",
    "        if search_word == \"Go\":\n",
    "            search_word = ' ' + search_word + ' '\n",
    "        \n",
    "        # Lower the word if it's not an abbreviation\n",
    "        elif search_word not in abbreviations:\n",
    "            search_word = search_word.lower()\n",
    "        \n",
    "        # Count occurence of searching word (case sensitive)\n",
    "        oc = text.count(search_word)\n",
    "        \n",
    "        # Append to the dictionary if the word occurs 1 or more time\n",
    "        if oc > 0:\n",
    "            d[display_word] = oc\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install pdfPlumber package\n",
    "# pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import io\n",
    "import requests\n",
    "\n",
    "def readPDF(url):\n",
    "    ''' \n",
    "    Read PDF file from a URL\n",
    "    Return a text string\n",
    "    '''\n",
    "    r = requests.get(url)\n",
    "    f = io.BytesIO(r.content)\n",
    "    text = \"\" # returned text\n",
    "    try:\n",
    "        # Open pdf file\n",
    "        with pdfplumber.open(f) as pdf:\n",
    "            pages = pdf.pages\n",
    "            # Iterate through pdf document pages\n",
    "            for page in pages:\n",
    "                # Concat page content to text if there are any\n",
    "                if page.extract_text():\n",
    "                    text += '\\n' + page.extract_text()\n",
    "\n",
    "        return text\n",
    "    except:\n",
    "        print(\"PDF file is not found!\")\n",
    "        return \"\"\n",
    "    \n",
    "\n",
    "def keywordsFromPaper(url, keywords):\n",
    "    '''\n",
    "    Extracts keywords from a pdf document\n",
    "      String url: a url of a pdf file\n",
    "      Dict keywords: a dictionary of searched word and displayed word\n",
    "    Return\n",
    "      A list of five words that have highest occurences \n",
    "    '''\n",
    "    text = readPDF(url).lower()\n",
    "    \n",
    "    if not text:\n",
    "        global n_pdf_unavil\n",
    "        n_pdf_unavil += 1\n",
    "        \n",
    "    occ = countKeywords(text, keywords)\n",
    "\n",
    "    # get a list of top 5 words\n",
    "    result = list(dict(sorted(occ.items(), key=lambda x: x[1], reverse=True)).keys())[:5]\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pdf_unavil = 0\n",
    "for paper in papers:\n",
    "    print(paper['url'])\n",
    "    paper['keywords'] = keywordsFromPaper(paper['url'], keywords)\n",
    "    print(paper['keywords'])\n",
    "    print(n_pdf_unavil)\n",
    "    print()\n",
    "print(n_pdf_unavil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding\n",
    "We successfully generate 4-5 keywords for most papers. \n",
    "\n",
    "\n",
    "Many URLs that the PDF file is unavilable: \n",
    "1. https://arxiv.org/pdf/0704.0213\n",
    "2. https://arxiv.org/pdf/0704.1409\n",
    "3. https://arxiv.org/pdf/0705.1442\n",
    "4. https://arxiv.org/pdf/0707.0454\n",
    "5. https://arxiv.org/pdf/0706.1002\n",
    "6. https://arxiv.org/pdf/0706.0484\n",
    "7. https://arxiv.org/pdf/0706.1118\n",
    "8. https://arxiv.org/pdf/0706.1477\n",
    "9. https://arxiv.org/pdf/0706.2073\n",
    "10. https://arxiv.org/pdf/0706.2153\n",
    "\n",
    "and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleansing\n",
    "Let's clean text for further machine learning works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import string\n",
    "import copy\n",
    "\n",
    "# Funtion to remove HTML tags\n",
    "def removeHTMLTags(text):\n",
    "    return BeautifulSoup(text, 'html.parser').get_text()\n",
    "\n",
    "# Function to remove more special characters and escape characters\n",
    "def removeExtraWhitespaceEsc(text):\n",
    "    #pattern = r'^\\s+$|\\s+$'\n",
    "    pat = r'^\\s*|\\s\\s*'\n",
    "    return re.sub(pat, ' ', text).strip()\n",
    "\n",
    "# Function to remove commas and periods\n",
    "def removeCommasPeriods(text):\n",
    "    pat = r'[.,]+'\n",
    "    return re.sub(pat, '', text)\n",
    "\n",
    "# Function to remove words that include special character\n",
    "def removeSpecialCharacterWords(text):\n",
    "    # define the pattern to keep only letters, numbers, dash and white spaces\n",
    "    pat = r'[a-zA-Z0-9]*[^a-zA-Z0-9_\\s]+[a-zA-Z0-9]*'\n",
    "    return re.sub(pat, '', text)\n",
    "\n",
    "def cleanText(text):\n",
    "    clean_text = removeHTMLTags(text)\n",
    "    clean_text = removeExtraWhitespaceEsc(clean_text)\n",
    "    clean_text = removeCommasPeriods(clean_text)\n",
    "    clean_text = removeSpecialCharacterWords(clean_text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample paper\n",
    "\n",
    "# Keywords from doing keywords matching\n",
    "# ['Probability', 'Statistics', 'Graphs', 'Image Processing', 'Signal Processing']\n",
    "\n",
    "url = \"https://arxiv.org/pdf/0705.0043.pdf\"\n",
    "text = readPDF(url)\n",
    "clean_text = cleanText(text)\n",
    "clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download \"en_core_sci_lg\"\n",
    "# pip install scispacy\n",
    "# pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_core_sci_lg-0.4.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_sci_lg\")\n",
    "kws = nlp(clean_text)\n",
    "kws.ents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 YAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Install yake\n",
    "# pip install yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yake\n",
    "\n",
    "kw_extractor = yake.KeywordExtractor()\n",
    "language = \"en\"\n",
    "max_ngram_size = 2\n",
    "deduplication_threshold = 0.1\n",
    "numOfKeywords = 20\n",
    "custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold, top=numOfKeywords, features=None)\n",
    "yake_kws = custom_kw_extractor.extract_keywords(clean_text)\n",
    "yake_kws\n",
    "    \n",
    "# The lower the score, the more relevant the keyword is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Rake-Nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Rake-Nltk\n",
    "# pip install rake-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rake_nltk import Rake\n",
    "r = Rake(max_length=3)  # uses stopwords for english from NLTK, and all puntuation characters\n",
    "\n",
    "# Keywords from title\n",
    "r.extract_keywords_from_text(clean_text)\n",
    "rake_kws = r.get_ranked_phrases()\n",
    "rake_kws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Gensim\n",
    "# !python -m pip install gensim==3.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization import keywords\n",
    "gensim_kws = keywords(clean_text)\n",
    "gensim_kws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding\n",
    "The text that we read from online pdf files is not in a good shape, e.g. no white space between words. This make it hard for machine learning algorithms to work well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
